{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b4476da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import xlwt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5054d58",
   "metadata": {},
   "source": [
    "### 抓去给定网页的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee80314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askURL(url):\n",
    "    # 设置为浏览器Header的User-Agent\n",
    "    header = {\n",
    "        'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.3 Safari/605.1.15'\n",
    "    }\n",
    "    \n",
    "    # 发送请求\n",
    "    request = urllib.request.Request(url, headers = header)\n",
    "    try:\n",
    "        # 取得响应\n",
    "        response = urllib.request.urlopen(request)\n",
    "        # 网页整体内容\n",
    "        html = response.read()\n",
    "        print(\"%s crawl success\" % url)\n",
    "    except urllib.error.URLError as e:\n",
    "        print(\"%s crawl fail\" % url)\n",
    "        if hasattr(e, 'code'):\n",
    "            print(e.code)\n",
    "        if hasattr(e, 'reason'):\n",
    "            print(e.reason)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f968885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取相关内容\n",
    "def getData(baseurl):\n",
    "    findLink=re.compile(r'<a href=\"(.*?)\">')#找到影片详情链接\n",
    "    findImgSrc=re.compile(r'<img.*src=\"(.*?)\"',re.S)#找到影片图片\n",
    "    findTitle=re.compile(r'<span class=\"title\">(.*)</span>')#找到片名\n",
    "    #找到评分\n",
    "    findRating=re.compile(r'<span class=\"rating_num\" property=\"v:average\">(.*)</span>')\n",
    "    #找到评价人数\n",
    "    findJudge=re.compile(r'<span>(\\d*)人评价</span>')\n",
    "    #找到概况\n",
    "    findInq=re.compile(r'<span class=\"inq\">(.*)</span>')\n",
    "    #找到影片相关内容：导演，主演，年份，地区，类别\n",
    "    findBd=re.compile(r'<p class=\"\">(.*?)</p>',re.S)\n",
    "    #去掉无关内容\n",
    "    remove=re.compile(r' |\\n|</br>|\\.*')\n",
    "    datalist=[]\n",
    "    for i in range(0,10):\n",
    "        url=baseurl+str(i*25)\n",
    "        # print(url)\n",
    "        html=askURL(url)\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        for item in soup.find_all('div',class_='item'):#找到每一个影片项\n",
    "            data=[]\n",
    "            item=str(item)#转换成字符串\n",
    "            # 影片详情链接\n",
    "            link=re.findall(findLink,item)[0]\n",
    "            data.append(link)#添加详情链接  \n",
    "            imgSrc=re.findall(findImgSrc,item)[0]\n",
    "            data.append(imgSrc)#添加图片链接\n",
    "            titles=re.findall(findTitle,item)\n",
    "            #片名可能只有一个中文名，没有外国名\n",
    "            if(len(titles)==2):\n",
    "                ctitle=titles[0]\n",
    "                data.append(ctitle)#添加中文片名\n",
    "                otitle=titles[1].replace(\"/\",\"\")#去掉无关符号\n",
    "                data.append(otitle)#添加外国片名\n",
    "            else:\n",
    "                data.append(titles[0])#添加中文片名\n",
    "                data.append(' ')#留空\n",
    "                \n",
    "            rating=re.findall(findRating,item)[0]\n",
    "            data.append(rating)#添加评分\n",
    "            judgeNum=re.findall(findJudge,item)[0]\n",
    "            data.append(judgeNum)#添加评论人数\n",
    "            inq=re.findall(findInq,item)\n",
    "            #可能没有概况\n",
    "            if len(inq)!=0:\n",
    "                inq=inq[0].replace(\"。\",\"\")#去掉句号\n",
    "                data.append(inq)#添加概况\n",
    "            else:\n",
    "                data.append(' ')#留空\n",
    "            bd=re.findall(findBd,item)[0]\n",
    "            bd=re.sub(remove,\"\",bd)\n",
    "            bd=re.sub('<br(\\s+)?\\/?>(\\s+)?',\" \",bd) #去掉<br >\n",
    "            bd=re.sub('/', \" \",bd)#替换/\n",
    "            data.append(bd.strip())\n",
    "            datalist.append(data)\n",
    "    return datalist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61a56496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将相关数据写入excel中\n",
    "def saveData(datalist,savepath):\n",
    "    col=['电影详情链接','图片链接','影片中文名','影片外国名',\n",
    "                '评分','评价数','概况','相关信息']\n",
    "    \n",
    "    df = pd.DataFrame(datalist, columns=col)\n",
    "    df.to_excel(savepath, sheet_name=\"豆瓣电影\")\n",
    "    \"\"\"\n",
    "    book=xlwt.Workbook(encoding='utf-8',style_compression=0)\n",
    "    sheet=book.add_sheet('豆瓣电影',cell_overwrite_ok=True)\n",
    "    col=('电影详情链接','图片链接','影片中文名','影片外国名',\n",
    "                '评分','评价数','概况','相关信息')\n",
    "    for i in range(0,8):\n",
    "        sheet.write(0,i,col[i])#列名\n",
    "    for i in range(0,250):\n",
    "        data=datalist[i]\n",
    "        for j in range(0,8):\n",
    "            sheet.write(i+1,j,data[j])#数据\n",
    "    book.save(savepath)#保存\n",
    "    \"\"\"\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f44cdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始爬取......\n",
      "https://movie.douban.com/top250?start=0 crawl success\n",
      "https://movie.douban.com/top250?start=25 crawl success\n",
      "https://movie.douban.com/top250?start=50 crawl success\n",
      "https://movie.douban.com/top250?start=75 crawl success\n",
      "https://movie.douban.com/top250?start=100 crawl success\n",
      "https://movie.douban.com/top250?start=125 crawl success\n",
      "https://movie.douban.com/top250?start=150 crawl success\n",
      "https://movie.douban.com/top250?start=175 crawl success\n"
     ]
    }
   ],
   "source": [
    "print (\"开始爬取......\")\n",
    "baseurl='https://movie.douban.com/top250?start='\n",
    "datalist=getData(baseurl)\n",
    "print(\"爬取完成......\")\n",
    "\n",
    "savapath=u'豆瓣电影.xlsx'\n",
    "df = saveData(datalist,savapath)\n",
    "\n",
    "# df = pd.read_excel(savapath)\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "matplotlib.rcParams['font.size']=20\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(df['评分'],range(1,251))\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('rank')\n",
    "\n",
    "#集中趋势的直方图\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(df['评分'],bins=15)\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('number')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c908e3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d417e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
